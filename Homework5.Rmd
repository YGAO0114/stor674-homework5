---
title: "Homework 5: Version Control, Containerization, and HPC"
author: "STOR 674"
date: "Due: 11/21/2025"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: united
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# Overview

This homework will test your knowledge of version control with Git/GitHub, containerization with Docker, and high-performance computing with Apptainer and Slurm. You will:

1. Answer conceptual questions about Git and GitHub
2. **Create a GitHub repository and version control your Docker image build process (with branching and merging)**
3. Build a Docker image for the Linux environment and push it to Docker Hub
4. Download and run the image on Longleaf using Apptainer and Slurm

**Note:** You may be working on macOS or Windows, but you'll be building Linux containers that will run on Longleaf's Linux HPC environment.

**Total Points: 100**

**Important:** You will need to submit:
- A PDF/HTML version of this completed Rmd file with your answers
- A link to your GitHub repository
- A link to your Docker Hub image
- Your Slurm job script
- Screenshot/output of your Slurm job completion

---

# Part 1: Git and GitHub Concepts (20 points)

## Question 1.1: Understanding Commits (5 points)

**a)** (3 points) What does a commit do in Git? Explain what information is stored in a commit.

**Answer:**
commit records a snapshot of the project’s files at a specific point in time. It represents a saved version of our work.    
in each commit, it stores: what changes does the user made such as adding/deleting files, modifying files; metadata such as author’s name, email, date, and time of the commit; a unique commit ID which is a identifier that allows Git to track and reference that specific snapshot, along with a message written by us describing the purpose of the changes.

**b)** (2 points) Why is it important to write descriptive commit messages? Provide an example of a good commit message and a bad commit message.

**Answer:**
it is important because it helps us understand what changes were made and why without having to look through the code. Clear messages make collaboration, debugging, and project history tracking much easier.   
Good commit message:  
Add data augmentation step to preprocessing pipeline
Bad commit message:  
fixed stuff


## Question 1.2: Branching in Git (10 points)

**a)** (5 points) Explain how branching works in Git. What happens when you create a new branch? What command would you use to create a new branch called `feature-analysis` and switch to it?

**Answer:**
branching allows us to create separate lines of development so can work on new features, experiments, or fixes without affecting the main codebase. When creating a new branch, Git makes a pointer to the current commit, meaning the new branch starts with the same project history as the branch we were on. Any new commits made on this branch will move its pointer forward, leaving other branches unchanged.

git branch feature-analysis      # creates the new branch.  
git checkout feature-analysis    # switches to that branch.   


**b)** (5 points) Git branching is often described as "super lightweight" compared to other version control systems. Explain why Git branching is lightweight. (Hint: Think about how Git stores branches and what happens under the hood when you create a branch.)

**Answer:**

because a branch is simply a pointer/reference to a specific commit in the repository’s history instead of a full copy of the project’s files.
When creating a new branch, Git adds a small file in the .git/refs/heads directory that contains the commit hash it points to. This operation takes up almost no extra space and happens instantly. when making new commits, Git only updates that pointer to the latest commit, rather than duplicating the project data.


## Question 1.3: Merging Branches (5 points)

**a)** (3 points) What is the purpose of merging branches? Describe the steps you would take to merge a branch called `feature-analysis` into the `main` branch.

**Answer:**

The purpose of merging branches is to combine the changes from one branch into another, which usually is the main branch. This allows us to integrate new work back into the main codebase after testing or development.

Steps to merge feature-analysis into main:   
1. Switch to the target branch (main):    
git checkout main

2.Update it to the latest version:   
git pull

3.Merge the feature branch into main:   
git merge feature-analysis

4.Resolve any merge conflicts if they occur, then commit the merge.

A merge conflict happens when Git cannot automatically combine changes from two branches because both branches have modified the same part of a file or one branch deleted a file that the other changed.

**b)** (2 points) What is a merge conflict and when does it occur?

**Answer:**

A merge conflict occurs when Git tries to combine two branches but finds overlapping changes that it cannot automatically resolve. This usually happens when two people edit the same line of a file, or when one branch deletes a file that another branch modifies. In such cases, Git stops the merge and asks the user to manually choose which changes to keep before completing the merge.


---

# Part 2: Docker Image Creation and Deployment with Version Control (50 points)

In this section, you will create a Docker image that can run the `compute_bench.py` script (which you used in Homework 2), which benchmarks CPU/GPU performance using PyTorch. **You will version control the entire process using Git and GitHub, practicing branching and merging workflows.**

**Important Note on Operating Systems:** You may be working on macOS or Windows, but Docker containers run Linux by default. You will be building a **Linux-based container** that will run on Longleaf (which is also Linux). Docker handles the cross-platform compatibility automatically, so your Linux container built on macOS/Windows will work seamlessly on Longleaf's Linux environment.

## Question 2.0: GitHub Repository Setup (5 points)

Before building your Docker image, you will set up version control for your project.

**a)** (1 points) Create a new GitHub repository called `stor674-homework5` (or similar name). Initialize it with a README. Provide the GitHub repository URL.

**GitHub Repository URL:**

https://github.com/your-username/stor674-homework5


**b)** (2 points) Clone the repository to your local machine, add the provided files (`compute_bench.py`, this `Homework5.Rmd`), and make your initial commit. What commands did you use?

**Answer:**

```bash

git clone https://github.com/your-username/stor674-homework5.git

cd stor674-homework5

cp /nas/longleaf/home/gyuan/STOR674/compute_bench.py .
cp /nas/longleaf/home/gyuan/STOR674/Homework5.Rmd .

git add compute_bench.py Homework5.Rmd

git commit -m "Add compute_bench.py and Homework5.Rmd files for Homework 5"

git push origin main

git status
```

**c)** (2 points) Create a new branch called `docker-build` where you will develop your Dockerfile. What command did you use? Why is it good practice to use a separate branch for development instead of working directly on `main`?

**Answer:**

```bash
# Command to create and switch to branch
git checkout -b docker-build

```

**Explanation:**

<!-- Why use a separate branch? -->
because it allows us to work on new features or experiments without affecting the main branch. This way, we can develop, test, and fix issues safely. Once the work is complete and verified, we can merge it back into main, keeping the main branch clean and production ready.

## Question 2.1: Understanding compute_bench.py (5 points)

**a)** (3 points) Read the `compute_bench.py` script. What does this script do? What is its main purpose?

**Answer:**

The compute_bench.py script benchmarks computational performance on a CPU and GPU using PyTorch. It generates large random tensors, performs mathematical operations (x = torch.randn(n) ** 4), and measures how long these computations take on each device.
The main purpose of the script is to compare the speed difference between CPU and GPU computations, helping users understand the performance benefits of GPU acceleration. It also demonstrates reproducibility (by setting a random seed), outputs timing results, and saves a small tensor sample to a file (mydata.pt) for reference.


**b)** (2 points) What Python packages does `compute_bench.py` require?

**Answer:**

<!-- Write your answer here -->
equired packages:

torch

time 

## Question 2.2: Create a Dockerfile (10 points)

Create a Dockerfile that:
- Uses an appropriate **Linux-based** base image with Python 3.9 or later
- Installs the required Python packages (PyTorch with CUDA support for GPU computing)
- Copies `compute_bench.py` into the container
- Sets the default command to run the script

**Important Considerations:**

- **Operating System**: Even if you're on macOS or Windows, Docker will build a Linux container. Use Linux base images (e.g., `python:3.9-slim` is based on Debian Linux).

- **CUDA Support**: Longleaf has NVIDIA GPUs. To enable GPU support in your container:
  - Option 1: Use official PyTorch image with CUDA: `pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime`
  - Option 2: Install PyTorch with CUDA support: `pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118`
  - Note: The container itself doesn't need NVIDIA drivers (Longleaf provides those), but PyTorch needs to be CUDA-aware.

- **Testing Locally**: If your computer doesn't have an NVIDIA GPU, the container will still build and run (it will just use CPU). On Longleaf with GPU nodes, it will automatically detect and use the GPU.

**Instructions:**

1. Make sure you're on the `docker-build` branch
2. Create a file named `Dockerfile` in your repository
3. Write the Dockerfile content below:

```dockerfile
# Base image with PyTorch + CUDA
FROM pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime

# Install minimal extras you might want (optional) and keep image slim
RUN pip install --no-cache-dir --upgrade pip

# Set a working directory inside the container
WORKDIR /app

# Copy the benchmarking script into the image
COPY compute_bench.py /app/compute_bench.py

# Default command: run the benchmark script
CMD ["python", "compute_bench.py"]




```


**Grading Criteria:**
- Appropriate Linux base image selection (2 points)
- CUDA-enabled PyTorch installation (4 points)
- Proper file copying (2 points)
- Correct CMD or ENTRYPOINT (2 points)

## Question 2.3: Build and Test Docker Image (10 points)

**a)** (3 points) What command did you use to build your Docker image? Include the full command and explain each part.

**Answer:**

```bash
# used on my own mac
docker build -t compute-bench .

# use in Longleaf:
singularity pull pytorch-cuda.sif docker://pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime

```

**Explanation:**

<!-- Explain each part of your command -->
docker build: The Docker command to build an image from a Dockerfile

-t compute-bench: Tags the image with the name "compute-bench" for easy reference

.: Specifies the build context as the current directory like where the Dockerfile is located


**b)** (4 points) What command did you use to run your Docker image locally to test it? Include the output you received.

**Answer:**

```bash
# Your command here
# used on my own mac
docker run compute-bench

# actually use in Longleaf:
singularity exec --nv --bind $(pwd):/workspace pytorch-cuda.sif python /workspace/compute_bench.py
```

**Output:**

```
# Paste the output here

# on my own mac
(base) yuangao@Yuans-MacBook-Pro-2 stor674-homework5 % docker run compute-bench
WARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested
No GPU available, running on CPU only

CPU Computations:
Time for 10,000,000 elements: 0.2455 seconds
Time for 100,000,000 elements: 2.0322 seconds

Small sample of 10 random numbers:
tensor([-0.1326, -1.5500,  1.1859,  1.5597,  0.7008, -0.4011, -1.1648,  0.1153,
        -0.3273, -0.3363])

Saved data to mydata.pt

# in Longleaf
(base) [gyuan@g181006 stor674-homework5]$ singularity exec --nv --bind $(pwd):/workspace pytorch-cuda.sif python /workspace/compute_bench.py
GPU available: NVIDIA L40S

CPU Computations:
Time for 10,000,000 elements: 0.2595 seconds
Time for 100,000,000 elements: 1.1891 seconds

GPU Computations:
Time for 10,000,000 elements: 4.7255 seconds
Time for 100,000,000 elements: 0.0025 seconds

Small sample of 10 random numbers:
tensor([ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,
         0.4617,  0.2674])

Saved data to mydata.pt

```

**c)** (3 points) Were there any issues you encountered during the build or test? How did you resolve them?

**Answer:**

<!-- Write your answer here -->
When testing on Longleaf, I encountered the issue that Docker is not available on the compute nodes. Longleaf uses Singularity/Apptainer instead for security and HPC compatibility reasons.
To resolve this:
I tested the Docker build locally on my machine where Docker is available
For running on Longleaf, I documented how to use Singularity to run the same container:
```bash
singularity exec --nv docker://pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime python compute_bench.py
```
container works fine on my own mac.


## Question 2.4: Version Control Your Docker Build (10 points)

Now that you have a working Dockerfile, let's commit it and merge it into the main branch.

**a)** (3 points) On your `docker-build` branch, add and commit your Dockerfile with a descriptive commit message. What commands did you use?

**Answer:**

```bash
# Make sure on the docker-build branch
git checkout docker-build

# Commands to add and commit Dockerfile
git add Dockerfile
git commit -m "Add Dockerfile to build PyTorch CUDA benchmark container"


```

**b)** (4 points) Switch to the `main` branch and merge the `docker-build` branch into it. What commands did you use? Paste the merge message or output.

**Answer:**

```bash
# Commands to switch branch and merge
git checkout main
git merge docker-build



```

**Merge Output:**

```
# Paste merge output here
(base) [gyuan@g181006 stor674-homework5]$ git checkout main
Switched to branch 'main'
Your branch is up to date with 'origin/main'.
(base) [gyuan@g181006 stor674-homework5]$ git merge docker-build
Updating 54f94b6..aecfd99
Fast-forward
 Dockerfile | 15 +++++++++++++++
 1 file changed, 15 insertions(+)
 create mode 100644 Dockerfile

```

**c)** (3 points) Push your changes to GitHub. Verify that your repository now contains the Dockerfile on the main branch. What command did you use to push?

**Answer:**

```bash
# Command to push to GitHub
git push origin main

# Due to authentication on Longleaf, configured SSH:
git remote set-url origin git@github.com:YGAO0114/stor674-homework5.git
git push origin main

```

**Verification:** Visit your GitHub repository in a web browser and confirm the Dockerfile is visible. ✓


## Question 2.5: Push to Docker Hub (10 points)

**a)** (3 points) Create a Docker Hub account (if you don't have one) and provide your Docker Hub username.

**Docker Hub Username:**

<!-- Your username here -->
ygaooo0114


**b)** (4 points) Tag your image appropriately and push it to Docker Hub. What commands did you use?

**Answer:**

```bash
# Commands you used
docker login

docker tag compute-bench ygaooo0114/compute-bench:latest

docker push ygaooo0114/compute-bench:latest


```

**c)** (3 points) Provide the full Docker Hub image URL/name that others can use to pull your image.

**Image URL:**

```
# Format: username/imagename:tag
ygaooo0114/compute-bench:latest


# output:
The push refers to repository [docker.io/ygaooo0114/compute-bench]
98db1a6c741e: Pushed 
b6e2ba0c0221: Pushed 
c10c6ab20f11: Pushed 
f427d480fa2f: Pushed 
b70d2f90ac5d: Pushed 
de2ec6e017a1: Pushed 
4f4fb700ef54: Pushed 
7ba52adfaf65: Pushed 
0c5227665c11: Pushed 
b04e68d40204: Pushed 
latest: digest: sha256:5d7304da8498cb3f0edcd908cf261462650d37620e8730162aa51c59d37f292d size: 856

```

---

# Part 3: Apptainer and Slurm on Longleaf (30 points)

In this section, you will download your Docker image using Apptainer on UNC's Longleaf cluster and submit a job using Slurm. Remember: your Linux container built on macOS/Windows will run seamlessly on Longleaf's Linux environment.

## Question 3.1: Understanding Apptainer (5 points)

**a)** (3 points) What is Apptainer (formerly Singularity) and why is it used on HPC systems instead of Docker?

**Answer:**

<!-- Write your answer here -->
Apptainer is a container platform designed specifically for HPC environments. It's used instead of Docker on HPC systems because:

It doesn't require root/sudo privileges to run containers

It provides better security by running containers as the user rather than root

It integrates seamlessly with HPC schedulers like Slurm

It supports MPI and GPU workloads natively

It can import Docker images while maintaining security boundaries


**b)** (2 points) What does "Bring Your Own Environment" (BYOE) mean in the context of HPC and containers?

**Answer:**

<!-- Write your answer here -->
BYOE means researchers can package their entire software environment (OS, libraries, dependencies) into a portable container that runs consistently across different HPC systems. This eliminates "it works on my machine" problems and ensures reproducibility regardless of the underlying cluster configuration.


## Question 3.2: Convert Docker Image to Apptainer (10 points)

**a)** (5 points) Log into Longleaf and use Apptainer to pull your Docker image from Docker Hub. What command did you use?

**Answer:**

```bash
# Command to pull/convert Docker image to Apptainer
apptainer pull docker://ygaooo0114/compute-bench:latest


# The Docker image built on my macOS was for ARM64 architecture, while Longleaf requires linux/amd64. To resolve this, I used the base PyTorch image directly from Docker Hub, which has multi-platform support. This demonstrates the same functionality as my custom image would provide.
# Using base PyTorch image instead:
singularity pull pytorch-cuda.sif docker://pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime


```


**b)** (3 points) What is the name of the Apptainer image file (.sif) that was created?

**Answer:**

```
# Filename here
compute-bench_latest.sif

pytorch-cuda.sif

```

**c)** (2 points) Test your Apptainer image interactively. What command did you use to run it?

**Answer:**

```bash
# Command to run Apptainer image
apptainer run compute-bench_latest.sif

# Run with the container and my script
singularity exec --nv pytorch-cuda.sif python compute_bench.py


# output:
GPU available: NVIDIA GeForce GTX 1080

CPU Computations:
Time for 10,000,000 elements: 0.2430 seconds
Time for 100,000,000 elements: 1.7256 seconds

GPU Computations:
Time for 10,000,000 elements: 6.0765 seconds
Time for 100,000,000 elements: 0.0063 seconds

Small sample of 10 random numbers:
tensor([ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,
         0.4617,  0.2674])

Saved data to mydata.pt
```

## Question 3.3: Create Slurm Job Script (12 points)

Create a Slurm job script that runs your containerized `compute_bench.py` using Apptainer.

**Hint:** If you want to test with GPU support on Longleaf, you'll need to:
- Request a GPU partition (e.g., `#SBATCH -p gpu`)
- Request GPU resources (e.g., `#SBATCH --gres=gpu:1`)
- Your CUDA-enabled PyTorch in the container will automatically use the GPU!

**Instructions:**

1. Create a file named `run_compute_bench.sh` in your GitHub repository
2. Include appropriate Slurm directives (partition, time, memory, etc.)
3. Load necessary modules (if needed)
4. Run the Apptainer container

**Your Slurm Script:**

```bash
# if can use the apptainer pull docker://ygaooo0114/compute-bench:latest

#!/bin/bash
#SBATCH --job-name=compute_bench_gpu
#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH --qos=gpu_access
#SBATCH --time=00:30:00
#SBATCH --mem=8G
#SBATCH --output=compute_bench_%j.out
#SBATCH --error=compute_bench_%j.err

# Load Apptainer module if needed
module load apptainer

# Print job information
echo "Job started on $(date)"
echo "Running on node: $(hostname)"
echo "Job ID: ${SLURM_JOB_ID}"

# Check GPU availability
nvidia-smi

# Run the containerized compute benchmark with GPU support
apptainer run --nv compute-bench_latest.sif

# Print completion time
echo "Job completed on $(date)"

```

```bash
# if use singularity pull pytorch-cuda.sif docker://pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime

#!/bin/bash
#SBATCH --job-name=compute_bench_gpu
#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH --qos=gpu_access
#SBATCH --time=00:30:00
#SBATCH --mem=8G
#SBATCH --output=compute_bench_%j.out
#SBATCH --error=compute_bench_%j.err

# Load Singularity module if needed
module load singularity

# Print job information
echo "Job started on $(date)"
echo "Running on node: $(hostname)"
echo "Job ID: ${SLURM_JOB_ID}"

# Check GPU availability
nvidia-smi

# Run the containerized compute benchmark with GPU support
singularity exec --nv pytorch-cuda.sif python compute_bench.py

# Print completion time
echo "Job completed on $(date)"
```

**Grading Criteria:**
- Appropriate Slurm directives (#SBATCH) (4 points)
- Correct Apptainer run command (6 points)
- Output redirection and job organization (2 points)

## Question 3.4: Submit, Verify, and Version Control (3 points)

**a)** (1 point) What command did you use to submit your job to Slurm?

**Answer:**

```bash
# Command here
sbatch run_compute_bench.sh
```

**b)** (2 points) Provide the output of your job. Paste the contents of your Slurm output file (e.g., `slurm-jobid.out`). Also, add your Slurm script (`run_compute_bench.sh`) to your GitHub repository and push it.

**Job Output:**

```
# Paste your job output here

Job started on Fri Nov 14 12:53:50 AM EST 2025
Running on node: g0602.ll.unc.edu
Job ID: 21994427
Fri Nov 14 00:53:50 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce GTX 1080        On  |   00000000:85:00.0 Off |                  N/A |
| 27%   30C    P8              6W /  180W |       3MiB /   8192MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
GPU available: NVIDIA GeForce GTX 1080

CPU Computations:
Time for 10,000,000 elements: 0.1934 seconds
Time for 100,000,000 elements: 1.5580 seconds

GPU Computations:
Time for 10,000,000 elements: 4.1265 seconds
Time for 100,000,000 elements: 0.0061 seconds

Small sample of 10 random numbers:
tensor([ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,
         0.4617,  0.2674])

Saved data to mydata.pt
Job completed on Fri Nov 14 12:54:00 AM EST 2025



```

**GitHub Verification:** ✓ Pushed `run_compute_bench.sh` to repository

**c)** (BONUS: +2 points) Include a screenshot showing your job in the Slurm queue or completed job information using `squeue` or `sacct`. Also show that your job successfully utilized a GPU (if you requested one).

```bash
(base) [gyuan@g0601 stor674-homework5]$ squeue -u $USER
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          21994427       gpu compute_    gyuan PD       0:00      1 (Priority)


(base) [gyuan@g0601 stor674-homework5]$ sacct -j 21994427 --format=JobID,JobName,Partition,State,ExitCode,Elapsed,ReqTRES
JobID           JobName  Partition      State ExitCode    Elapsed    ReqTRES 
------------ ---------- ---------- ---------- -------- ---------- ---------- 
21994427     compute_b+        gpu  COMPLETED      0:0   00:00:11 billing=1+ 
21994427.ba+      batch             COMPLETED      0:0   00:00:11            
21994427.ex+     extern             COMPLETED      0:0   00:00:11     
```

---

# Part 4: Reflection and Best Practices (Optional - Extra Credit: 5 points)

**Question 4.1:** Reflect on the workflow you just completed (Git → Docker → HPC). How does this approach improve reproducibility in computational research? What are some advantages and potential challenges?

**Answer:**

<!-- Write your answer here -->
it improves computational research reproducibility through several mechanisms:
Advantages:

Version Control (Git): Tracks all code changes, enabling researchers to reproduce exact versions of experiments and collaborate effectively across time and teams.

Environment Consistency (Docker/Apptainer): Containers package the entire computational environment including OS, libraries, and dependencies, eliminating "works on my machine" issues. The same container runs identically on a laptop or HPC cluster.

Platform Independence: Building on Mac/Windows and deploying on Linux HPC demonstrates true portability.

Researchers can develop locally and scale to HPC resources seamlessly.

Resource Efficiency: HPC integration through Slurm enables access to powerful GPU resources while containers ensure optimal utilization regardless of the host system configuration.

Reproducibility Chain: Anyone can clone the Git repo, pull the Docker image, and reproduce results exactly, even years later when system libraries have changed.

Challenges:

Architecture Compatibility: As experienced with ARM64 vs AMD64, multi-architecture support requires careful consideration.

Learning Curve: Researchers need to learn Git, containerization, and HPC job scheduling - a significant initial investment.

Storage Overhead: Container images can be large, and maintaining multiple versions consumes significant storage.

Security Constraints: HPC systems often use Singularity/Apptainer instead of Docker for security, requiring workflow adaptation.
---

# Submission Checklist

Before submitting, make sure you have:

- [ ] Completed all questions in Part 1 (Git/GitHub concepts)
- [ ] **Created a GitHub repository with all your project files**
- [ ] **Practiced branching and merging in your Git workflow**
- [ ] Created a Dockerfile with CUDA support for GPU computing
- [ ] Built and tested your Docker image locally (Linux container on macOS/Windows)
- [ ] Pushed your image to Docker Hub
- [ ] Provided your Docker Hub image URL
- [ ] Created a Slurm job script
- [ ] Successfully ran your job on Longleaf
- [ ] **Pushed all files (Dockerfile, Slurm script, completed Rmd) to GitHub**
- [ ] Included all output and screenshots
- [ ] Compiled this Rmd file to HTML or PDF

**Submission Instructions:**

1. **Ensure your GitHub repository contains:**
   - `Dockerfile`
   - `compute_bench.py`
   - `run_compute_bench.sh` (Slurm script)
   - `Homework5.Rmd` (completed)
   - Evidence of branching/merging in commit history
   
2. Submit the knitted HTML/PDF file on Canvas
3. **Submit the link to your GitHub repository on Canvas (REQUIRED)**
4. Submit the link to your Docker Hub image on Canvas

---

# Grading Rubric

| Section | Points |
|---------|--------|
| Part 1: Git and GitHub Concepts | 20 |
| Part 2: Docker with Version Control (includes branching/merging) | 50 |
| Part 3: Apptainer and Slurm on Longleaf | 30 |
| **Total** | **100** |
| Extra Credit (Part 4: Reflection) | +5 |
| Extra Credit (Part 3.4c: GPU screenshot) | +2 |
| **Maximum Possible** | **107** |

---

# Resources

- [Git Branching Documentation](https://git-scm.com/book/en/v2/Git-Branching-Branches-in-a-Nutshell)
- [Docker Hub](https://hub.docker.com/)
- [Apptainer Documentation](https://apptainer.org/docs/)
- [Longleaf Documentation](https://help.rc.unc.edu/longleaf-cluster/)
- Course lecture materials on GitHub, Docker, and Apptainer

---

**Good luck!**

